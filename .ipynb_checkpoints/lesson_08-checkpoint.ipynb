{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 8: Cross-validation\n",
    "\n",
    "So far, we've learned about splitting our data into training and testing sets to validate our models. This helps ensure that the model we create on one sample performs well on another sample we want to predict. \n",
    "\n",
    "However, we don't have to use just TWO samples to train and test our models. Instead, we can split our data up into MULTIPLE samples to train and test on multiple segments of the data. This is called CROSS-VALIDATION. This allows us to ensure that our model predicts outcomes over a wider range of circumstances. \n",
    "\n",
    "Let's begin by importing our packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(your_working_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we'll be looking at 311 service requests for rodent inspection and abatement aggregated at the Census block level. The data set is already prepared for you and available in the same folder as this assignment. Census blocks are a good geographic level to analyze rodent infestations because they are drawn along natural and human-made boundaries, like rivers and roads, that rats tend not to cross. \n",
    "\n",
    "We will look at the 'activity' variable, which indicates whether inspectors found rat burrows during an inspection (1) or not (0). Here we are looking only at inpsections in 2016. About 43 percent on inspections in 2016 led to inspectors finding and treating rat burrows, as you can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('rat_data_2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['activity', 'alley_condition', 'bbl_hotel', 'bbl_multifamily_rental',\n",
       "       'bbl_restaurant', 'bbl_single_family_rental', 'bbl_storage',\n",
       "       'bbl_two_family_rental', 'communitygarden_area', 'communitygarden_id',\n",
       "       'dcrapermit_addition', 'dcrapermit_demolition', 'dcrapermit_excavation',\n",
       "       'dcrapermit_new_building', 'dcrapermit_raze', 'impervious_area',\n",
       "       'month', 'num_mixed_use', 'num_non_residential', 'num_residential',\n",
       "       'park', 'pct_mixed_use', 'pct_non_residential', 'pct_residential',\n",
       "       'pop_density', 'sidewalk_grates', 'ssl_cndtn_Average_comm',\n",
       "       'ssl_cndtn_Average_res', 'ssl_cndtn_Excellent_comm',\n",
       "       'ssl_cndtn_Excellent_res', 'ssl_cndtn_Fair_comm', 'ssl_cndtn_Fair_res',\n",
       "       'ssl_cndtn_Good_comm', 'ssl_cndtn_Good_res', 'ssl_cndtn_Poor_comm',\n",
       "       'ssl_cndtn_Poor_res', 'ssl_cndtn_VeryGood_comm',\n",
       "       'ssl_cndtn_VeryGood_res', 'tot_pop', 'well_activity', 'WARD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>activity</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.431696</td>\n",
       "      <td>0.495408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alley_condition</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>11.111282</td>\n",
       "      <td>8.900166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbl_hotel</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.082118</td>\n",
       "      <td>0.376073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbl_multifamily_rental</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>1.388718</td>\n",
       "      <td>2.376244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbl_restaurant</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.569455</td>\n",
       "      <td>1.518526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbl_single_family_rental</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>4.709133</td>\n",
       "      <td>8.375165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>147.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbl_storage</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.051768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbl_two_family_rental</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.743668</td>\n",
       "      <td>1.378860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>communitygarden_area</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>18.727920</td>\n",
       "      <td>326.332382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11004.319881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>communitygarden_id</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.242134</td>\n",
       "      <td>3.234069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dcrapermit_addition</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.054490</td>\n",
       "      <td>0.265959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dcrapermit_demolition</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.280507</td>\n",
       "      <td>0.738300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dcrapermit_excavation</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.010361</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dcrapermit_new_building</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.053722</td>\n",
       "      <td>0.286938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dcrapermit_raze</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.044896</td>\n",
       "      <td>0.308390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impervious_area</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>18450.549489</td>\n",
       "      <td>18774.921307</td>\n",
       "      <td>2150.037473</td>\n",
       "      <td>11356.602831</td>\n",
       "      <td>14532.464194</td>\n",
       "      <td>19920.166029</td>\n",
       "      <td>473222.487756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>7.194935</td>\n",
       "      <td>3.001022</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_mixed_use</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.153876</td>\n",
       "      <td>0.474006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_non_residential</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>3.804682</td>\n",
       "      <td>5.956966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_residential</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>39.287797</td>\n",
       "      <td>26.661136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>334.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>park</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.046815</td>\n",
       "      <td>0.225350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_mixed_use</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>0.013706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_non_residential</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.139389</td>\n",
       "      <td>0.242231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_residential</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.854794</td>\n",
       "      <td>0.247308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.838200</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop_density</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>24969.466549</td>\n",
       "      <td>19217.566990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13524.013052</td>\n",
       "      <td>21965.055541</td>\n",
       "      <td>30907.352412</td>\n",
       "      <td>182709.507271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sidewalk_grates</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>2.109363</td>\n",
       "      <td>5.186348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssl_cndtn_Average_comm</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.402058</td>\n",
       "      <td>0.401132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssl_cndtn_Average_res</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.574651</td>\n",
       "      <td>0.265928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.635642</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssl_cndtn_Excellent_comm</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.022413</td>\n",
       "      <td>0.095254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssl_cndtn_Excellent_res</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.029081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssl_cndtn_Fair_comm</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.024810</td>\n",
       "      <td>0.101711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssl_cndtn_Fair_res</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.018239</td>\n",
       "      <td>0.047230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssl_cndtn_Good_comm</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.162147</td>\n",
       "      <td>0.261734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssl_cndtn_Good_res</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.285093</td>\n",
       "      <td>0.206829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.403509</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssl_cndtn_Poor_comm</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.002487</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssl_cndtn_Poor_res</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>0.010527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssl_cndtn_VeryGood_comm</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.104810</td>\n",
       "      <td>0.232111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssl_cndtn_VeryGood_res</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.036727</td>\n",
       "      <td>0.071472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_pop</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>188.892172</td>\n",
       "      <td>211.199274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well_activity</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>0.572141</td>\n",
       "      <td>1.569373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WARD</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>3.994244</td>\n",
       "      <td>2.112836</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           count          mean           std          min  \\\n",
       "activity                  2606.0      0.431696      0.495408     0.000000   \n",
       "alley_condition           2606.0     11.111282      8.900166     0.000000   \n",
       "bbl_hotel                 2606.0      0.082118      0.376073     0.000000   \n",
       "bbl_multifamily_rental    2606.0      1.388718      2.376244     0.000000   \n",
       "bbl_restaurant            2606.0      0.569455      1.518526     0.000000   \n",
       "bbl_single_family_rental  2606.0      4.709133      8.375165     0.000000   \n",
       "bbl_storage               2606.0      0.002686      0.051768     0.000000   \n",
       "bbl_two_family_rental     2606.0      0.743668      1.378860     0.000000   \n",
       "communitygarden_area      2606.0     18.727920    326.332382     0.000000   \n",
       "communitygarden_id        2606.0      0.242134      3.234069     0.000000   \n",
       "dcrapermit_addition       2606.0      0.054490      0.265959     0.000000   \n",
       "dcrapermit_demolition     2606.0      0.280507      0.738300     0.000000   \n",
       "dcrapermit_excavation     2606.0      0.010361      0.105000     0.000000   \n",
       "dcrapermit_new_building   2606.0      0.053722      0.286938     0.000000   \n",
       "dcrapermit_raze           2606.0      0.044896      0.308390     0.000000   \n",
       "impervious_area           2606.0  18450.549489  18774.921307  2150.037473   \n",
       "month                     2606.0      7.194935      3.001022     1.000000   \n",
       "num_mixed_use             2606.0      0.153876      0.474006     0.000000   \n",
       "num_non_residential       2606.0      3.804682      5.956966     0.000000   \n",
       "num_residential           2606.0     39.287797     26.661136     0.000000   \n",
       "park                      2606.0      0.046815      0.225350     0.000000   \n",
       "pct_mixed_use             2606.0      0.003899      0.013706     0.000000   \n",
       "pct_non_residential       2606.0      0.139389      0.242231     0.000000   \n",
       "pct_residential           2606.0      0.854794      0.247308     0.000000   \n",
       "pop_density               2606.0  24969.466549  19217.566990     0.000000   \n",
       "sidewalk_grates           2606.0      2.109363      5.186348     0.000000   \n",
       "ssl_cndtn_Average_comm    2606.0      0.402058      0.401132     0.000000   \n",
       "ssl_cndtn_Average_res     2606.0      0.574651      0.265928     0.000000   \n",
       "ssl_cndtn_Excellent_comm  2606.0      0.022413      0.095254     0.000000   \n",
       "ssl_cndtn_Excellent_res   2606.0      0.001871      0.029081     0.000000   \n",
       "ssl_cndtn_Fair_comm       2606.0      0.024810      0.101711     0.000000   \n",
       "ssl_cndtn_Fair_res        2606.0      0.018239      0.047230     0.000000   \n",
       "ssl_cndtn_Good_comm       2606.0      0.162147      0.261734     0.000000   \n",
       "ssl_cndtn_Good_res        2606.0      0.285093      0.206829     0.000000   \n",
       "ssl_cndtn_Poor_comm       2606.0      0.002487      0.032450     0.000000   \n",
       "ssl_cndtn_Poor_res        2606.0      0.002067      0.010527     0.000000   \n",
       "ssl_cndtn_VeryGood_comm   2606.0      0.104810      0.232111     0.000000   \n",
       "ssl_cndtn_VeryGood_res    2606.0      0.036727      0.071472     0.000000   \n",
       "tot_pop                   2606.0    188.892172    211.199274     0.000000   \n",
       "well_activity             2606.0      0.572141      1.569373     0.000000   \n",
       "WARD                      2606.0      3.994244      2.112836     1.000000   \n",
       "\n",
       "                                   25%           50%           75%  \\\n",
       "activity                      0.000000      0.000000      1.000000   \n",
       "alley_condition               4.000000     10.000000     16.000000   \n",
       "bbl_hotel                     0.000000      0.000000      0.000000   \n",
       "bbl_multifamily_rental        0.000000      0.000000      2.000000   \n",
       "bbl_restaurant                0.000000      0.000000      0.000000   \n",
       "bbl_single_family_rental      1.000000      2.000000      5.000000   \n",
       "bbl_storage                   0.000000      0.000000      0.000000   \n",
       "bbl_two_family_rental         0.000000      0.000000      1.000000   \n",
       "communitygarden_area          0.000000      0.000000      0.000000   \n",
       "communitygarden_id            0.000000      0.000000      0.000000   \n",
       "dcrapermit_addition           0.000000      0.000000      0.000000   \n",
       "dcrapermit_demolition         0.000000      0.000000      0.000000   \n",
       "dcrapermit_excavation         0.000000      0.000000      0.000000   \n",
       "dcrapermit_new_building       0.000000      0.000000      0.000000   \n",
       "dcrapermit_raze               0.000000      0.000000      0.000000   \n",
       "impervious_area           11356.602831  14532.464194  19920.166029   \n",
       "month                         5.000000      7.000000     10.000000   \n",
       "num_mixed_use                 0.000000      0.000000      0.000000   \n",
       "num_non_residential           0.000000      1.000000      5.000000   \n",
       "num_residential              21.000000     36.000000     53.000000   \n",
       "park                          0.000000      0.000000      0.000000   \n",
       "pct_mixed_use                 0.000000      0.000000      0.000000   \n",
       "pct_non_residential           0.000000      0.038462      0.150000   \n",
       "pct_residential               0.838200      0.959184      1.000000   \n",
       "pop_density               13524.013052  21965.055541  30907.352412   \n",
       "sidewalk_grates               0.000000      0.000000      2.000000   \n",
       "ssl_cndtn_Average_comm        0.000000      0.333333      0.800000   \n",
       "ssl_cndtn_Average_res         0.444444      0.635642      0.767857   \n",
       "ssl_cndtn_Excellent_comm      0.000000      0.000000      0.000000   \n",
       "ssl_cndtn_Excellent_res       0.000000      0.000000      0.000000   \n",
       "ssl_cndtn_Fair_comm           0.000000      0.000000      0.000000   \n",
       "ssl_cndtn_Fair_res            0.000000      0.000000      0.017857   \n",
       "ssl_cndtn_Good_comm           0.000000      0.000000      0.250000   \n",
       "ssl_cndtn_Good_res            0.133333      0.266667      0.403509   \n",
       "ssl_cndtn_Poor_comm           0.000000      0.000000      0.000000   \n",
       "ssl_cndtn_Poor_res            0.000000      0.000000      0.000000   \n",
       "ssl_cndtn_VeryGood_comm       0.000000      0.000000      0.000000   \n",
       "ssl_cndtn_VeryGood_res        0.000000      0.000000      0.052632   \n",
       "tot_pop                      82.000000    137.000000    231.000000   \n",
       "well_activity                 0.000000      0.000000      0.000000   \n",
       "WARD                          2.000000      4.000000      6.000000   \n",
       "\n",
       "                                    max  \n",
       "activity                       1.000000  \n",
       "alley_condition               79.000000  \n",
       "bbl_hotel                      8.000000  \n",
       "bbl_multifamily_rental        22.000000  \n",
       "bbl_restaurant                17.000000  \n",
       "bbl_single_family_rental     147.000000  \n",
       "bbl_storage                    1.000000  \n",
       "bbl_two_family_rental         15.000000  \n",
       "communitygarden_area       11004.319881  \n",
       "communitygarden_id            80.000000  \n",
       "dcrapermit_addition            4.000000  \n",
       "dcrapermit_demolition         12.000000  \n",
       "dcrapermit_excavation          2.000000  \n",
       "dcrapermit_new_building        4.000000  \n",
       "dcrapermit_raze                5.000000  \n",
       "impervious_area           473222.487756  \n",
       "month                         12.000000  \n",
       "num_mixed_use                  4.000000  \n",
       "num_non_residential           58.000000  \n",
       "num_residential              334.000000  \n",
       "park                           4.000000  \n",
       "pct_mixed_use                  0.250000  \n",
       "pct_non_residential            1.000000  \n",
       "pct_residential                1.000000  \n",
       "pop_density               182709.507271  \n",
       "sidewalk_grates               73.000000  \n",
       "ssl_cndtn_Average_comm         1.000000  \n",
       "ssl_cndtn_Average_res          1.000000  \n",
       "ssl_cndtn_Excellent_comm       1.000000  \n",
       "ssl_cndtn_Excellent_res        0.766990  \n",
       "ssl_cndtn_Fair_comm            1.000000  \n",
       "ssl_cndtn_Fair_res             0.666667  \n",
       "ssl_cndtn_Good_comm            1.000000  \n",
       "ssl_cndtn_Good_res             1.000000  \n",
       "ssl_cndtn_Poor_comm            1.000000  \n",
       "ssl_cndtn_Poor_res             0.200000  \n",
       "ssl_cndtn_VeryGood_comm        1.000000  \n",
       "ssl_cndtn_VeryGood_res         1.000000  \n",
       "tot_pop                     3888.000000  \n",
       "well_activity                 19.000000  \n",
       "WARD                           8.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from last week that, when we do predictive analysis, we usually are not interested in the relationship between two different variables as we are when we do traditional hypothesis testing. Instead, we're interested in training a model that generates predictions that best fit our target population. Therefore, when we are doing any kind of validation, including cross-validation, it is important for us to choose the metric by which we will evaluate the performance of our models. \n",
    "\n",
    "For this model, we will predict the locations of requests for rodent inspection and abatement in the District of Columbia. When we select a validation metric, it's important for us to think about what we want to optimize. For example, do we want to make sure that our top predictions accurately identify places with rodent infestations, so we don't send our inspectors on a wild goose chase? Then we may to look at the models precision, or what proportion of its positive predictions turn out to be positive. Or do we want to make sure we don't miss any infestations? If so, we may want to look at recall, or the proportion of positive cases that are correctly categorized by the model. If we care a lot about how the model ranks our observations, then we may want to look at the area under the ROC curve, or ROC-AUC, while if we care more about how well the model fits the data, or its \"calibration,\" we may want to look at Brier score or logarithmic loss (log-loss).\n",
    "\n",
    "In the case of rodent inspections, we most likely want to make sure that we send our inspectors to places where they are most likely to find rats and to avoid sending them on wild goose [rat] chases. Therefore, we will optimize for precision, which we will call from the metrics library in scikit-learn. \n",
    "\n",
    "The metrics library in scikit-learn provides a number of different options. You should take some time to look at the different metrics that are available to you and consider which ones are most appropriate for your own research\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next important decision we need to make when cross-validating our models is how we will define our \"folds.\" Folds are the independent subsamples on which we train and test the data. Keep in mind that it is important that our folds are INDEPENDENT, which means we must guarantee that there's no overlap between our training and test set (i.e., no observation is in both the training and test set). Independence can also have other implications for how we slice the data, which we will discuss as we progress through this lesson.\n",
    "\n",
    "One of the most common approaches to cross-validation is to make random splits in the data. This is often referred to as k-fold cross-validation, in which the only thing we define is the number of folds (k) that want to split our sample into. Here, I'll use the KFold function from scikit-learn's model_selection library. Let's begin by importing the library and then taking a look at how it splits our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KFold divides our data into a pre-specified number of (approximately) equally-sized folds so that each observation is in the test set once. When we specify that shuffle=True, KFold first shuffles our data into a random order to ensure that the observations are randomly selected. By selecting a random_state, we can ensure that KFold selects observations the same way each time. \n",
    "\n",
    "While there are other functions in the model_selection library that will do much of this work for us, KFold will allow us to look at what's going on in the background of our cross-validation process. Let's begin by just looking at how KFold splits our data. Here we split our data into 10 folds each with 10 percent of the data (.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   0    1    2 ..., 2603 2604 2605] TEST: [   9   22   27   33   53   70   92  104  109  117  121  135  137  156  182\n",
      "  192  195  196  215  217  224  227  252  259  271  276  289  314  317  326\n",
      "  333  351  398  399  418  422  427  436  438  443  452  465  478  480  482\n",
      "  489  518  547  562  563  567  569  578  581  597  609  616  618  619  674\n",
      "  682  686  700  704  710  711  720  722  728  743  745  746  748  764  778\n",
      "  795  817  831  855  868  878  880  899  913  916  921  927  933  961  962\n",
      "  982  983  988  998 1000 1012 1013 1018 1023 1032 1036 1051 1052 1059 1078\n",
      " 1079 1096 1100 1101 1106 1108 1109 1147 1187 1192 1213 1263 1264 1285 1287\n",
      " 1300 1323 1326 1327 1371 1396 1418 1421 1432 1452 1484 1507 1515 1520 1544\n",
      " 1568 1570 1577 1580 1585 1588 1590 1592 1597 1622 1627 1656 1657 1668 1680\n",
      " 1681 1686 1689 1708 1710 1719 1729 1732 1735 1757 1761 1762 1763 1765 1780\n",
      " 1783 1790 1798 1803 1814 1816 1818 1820 1821 1827 1832 1836 1853 1873 1874\n",
      " 1895 1898 1901 1902 1921 1927 1929 1939 1943 1961 1968 1969 1972 1974 1979\n",
      " 1982 1989 1997 1998 2019 2027 2030 2033 2055 2074 2085 2087 2090 2115 2123\n",
      " 2134 2138 2151 2156 2161 2183 2186 2191 2225 2230 2254 2258 2274 2281 2289\n",
      " 2302 2312 2316 2317 2343 2345 2346 2358 2359 2378 2386 2387 2398 2400 2410\n",
      " 2416 2417 2419 2429 2450 2468 2498 2499 2502 2510 2520 2543 2544 2550 2555\n",
      " 2564 2567 2579 2585 2596 2597]\n",
      "TRAIN: [   0    1    2 ..., 2603 2604 2605] TEST: [   4   10   14   23   37   39   41   57   69   76   98  113  124  132  145\n",
      "  148  162  179  191  204  232  234  245  248  251  296  302  303  311  320\n",
      "  330  353  357  361  379  385  390  402  405  414  425  440  446  454  457\n",
      "  477  486  487  501  526  527  536  543  558  565  582  610  615  621  634\n",
      "  638  652  653  666  667  672  676  687  688  692  702  703  708  712  713\n",
      "  715  716  758  776  789  812  828  838  840  847  852  876  891  897  898\n",
      "  905  909  914  924  926  935  966  989  997 1002 1003 1025 1041 1068 1070\n",
      " 1091 1093 1110 1118 1122 1138 1146 1150 1161 1173 1185 1193 1197 1199 1210\n",
      " 1211 1222 1228 1231 1232 1239 1242 1244 1270 1292 1294 1303 1332 1334 1362\n",
      " 1366 1377 1380 1405 1412 1414 1424 1426 1449 1465 1467 1486 1487 1493 1496\n",
      " 1504 1506 1512 1525 1535 1539 1543 1548 1549 1553 1555 1573 1594 1599 1601\n",
      " 1625 1637 1642 1646 1663 1664 1665 1675 1678 1702 1703 1712 1714 1727 1728\n",
      " 1768 1770 1774 1781 1809 1813 1824 1825 1826 1839 1845 1851 1852 1859 1885\n",
      " 1928 1937 1946 1949 1952 1955 1988 2001 2007 2013 2037 2038 2045 2054 2067\n",
      " 2069 2073 2088 2095 2116 2131 2143 2149 2175 2201 2207 2213 2229 2233 2245\n",
      " 2246 2262 2266 2272 2276 2288 2293 2297 2321 2333 2341 2354 2356 2376 2381\n",
      " 2395 2399 2405 2409 2442 2482 2491 2497 2508 2512 2515 2526 2531 2556 2559\n",
      " 2561 2562 2566 2588 2592 2594]\n",
      "TRAIN: [   0    2    3 ..., 2603 2604 2605] TEST: [   1    6   11   17   18   30   40   47   48   52   58  107  125  133  149\n",
      "  157  161  173  175  189  194  200  206  220  229  249  254  264  283  286\n",
      "  300  305  322  342  384  386  391  392  411  442  444  453  458  459  461\n",
      "  488  503  505  517  529  530  535  538  557  568  570  574  575  579  587\n",
      "  596  602  641  646  648  651  657  661  665  670  684  723  727  731  757\n",
      "  762  768  792  805  841  850  886  892  895  900  906  918  936  949  951\n",
      "  953  963  995  996 1005 1009 1015 1017 1027 1042 1055 1058 1063 1073 1081\n",
      " 1098 1103 1116 1126 1127 1139 1140 1157 1160 1174 1188 1190 1203 1205 1226\n",
      " 1236 1246 1256 1267 1271 1273 1283 1295 1302 1317 1322 1328 1357 1367 1370\n",
      " 1373 1386 1393 1411 1422 1428 1431 1448 1450 1459 1471 1492 1503 1513 1521\n",
      " 1523 1528 1533 1540 1547 1567 1569 1598 1602 1621 1631 1632 1643 1673 1677\n",
      " 1697 1704 1713 1715 1724 1725 1726 1736 1737 1753 1754 1773 1802 1819 1829\n",
      " 1840 1854 1855 1861 1864 1867 1869 1872 1897 1900 1931 1942 1945 1947 1964\n",
      " 1983 1985 1996 1999 2012 2015 2026 2039 2052 2072 2083 2097 2099 2109 2124\n",
      " 2144 2145 2165 2188 2190 2198 2208 2223 2235 2238 2240 2249 2256 2279 2284\n",
      " 2285 2290 2300 2308 2320 2326 2336 2352 2355 2357 2367 2372 2382 2396 2407\n",
      " 2414 2422 2430 2432 2462 2467 2471 2477 2480 2495 2500 2511 2518 2525 2548\n",
      " 2549 2560 2569 2576 2582 2601]\n",
      "TRAIN: [   0    1    2 ..., 2603 2604 2605] TEST: [  15   31   34   43   61   64   77   80   85   87  106  118  139  141  144\n",
      "  169  187  202  223  233  240  250  253  260  262  267  270  279  287  294\n",
      "  295  298  299  309  310  359  360  369  376  381  393  415  474  475  483\n",
      "  485  491  502  506  512  516  519  521  522  532  546  553  564  572  600\n",
      "  620  629  633  636  643  654  655  663  701  721  733  735  766  775  781\n",
      "  791  793  794  799  806  810  815  818  820  825  829  832  836  842  861\n",
      "  882  883  890  896  910  917  923  937  938  944  946  958  964  971  977\n",
      "  979  980  981  986  991 1010 1038 1043 1045 1047 1049 1056 1074 1077 1083\n",
      " 1087 1097 1099 1114 1119 1136 1148 1151 1170 1180 1183 1212 1217 1240 1254\n",
      " 1255 1279 1301 1325 1330 1339 1341 1347 1355 1368 1374 1385 1388 1390 1397\n",
      " 1399 1417 1453 1458 1474 1485 1490 1491 1516 1559 1560 1571 1581 1587 1593\n",
      " 1603 1610 1611 1647 1648 1674 1694 1696 1709 1758 1759 1760 1779 1786 1787\n",
      " 1789 1801 1808 1817 1860 1865 1875 1876 1892 1903 1907 1916 1919 1923 1935\n",
      " 1948 1980 1994 2020 2032 2044 2050 2053 2057 2061 2063 2064 2075 2078 2092\n",
      " 2122 2129 2133 2140 2158 2164 2173 2178 2203 2204 2210 2219 2259 2263 2273\n",
      " 2296 2298 2305 2311 2319 2328 2351 2360 2391 2392 2394 2397 2401 2402 2406\n",
      " 2408 2413 2441 2444 2447 2457 2458 2469 2478 2479 2493 2507 2509 2519 2522\n",
      " 2536 2538 2571 2574 2575 2581]\n",
      "TRAIN: [   0    1    3 ..., 2602 2604 2605] TEST: [   2    5   19   36   42   45   54   55   65   66   72   73   82   89  102\n",
      "  108  122  140  142  152  154  159  170  171  177  178  184  185  190  198\n",
      "  203  210  214  219  268  272  278  308  312  315  318  319  335  340  341\n",
      "  347  364  378  383  408  412  416  434  467  468  473  479  481  498  511\n",
      "  534  539  551  561  583  590  598  632  644  658  689  717  718  724  726\n",
      "  740  744  750  759  760  772  773  785  796  801  811  813  823  839  856\n",
      "  863  866  893  930  955  965  974  978  985  987  992 1001 1008 1021 1026\n",
      " 1029 1050 1069 1076 1080 1082 1117 1129 1132 1135 1137 1145 1154 1165 1166\n",
      " 1175 1195 1216 1225 1235 1257 1259 1261 1266 1275 1277 1280 1284 1293 1338\n",
      " 1343 1349 1358 1359 1363 1376 1378 1379 1387 1423 1427 1454 1456 1457 1460\n",
      " 1462 1473 1478 1482 1489 1499 1500 1518 1526 1530 1537 1538 1550 1606 1612\n",
      " 1615 1633 1635 1661 1666 1679 1717 1742 1748 1749 1752 1764 1775 1785 1846\n",
      " 1848 1858 1878 1886 1890 1909 1914 1934 1950 1957 1960 1976 2000 2005 2010\n",
      " 2017 2018 2025 2028 2031 2034 2035 2056 2058 2093 2100 2102 2108 2119 2160\n",
      " 2166 2172 2181 2194 2202 2218 2228 2236 2242 2244 2248 2253 2264 2265 2267\n",
      " 2269 2270 2278 2283 2303 2310 2324 2325 2349 2364 2365 2393 2421 2434 2438\n",
      " 2452 2453 2456 2460 2463 2465 2475 2484 2485 2487 2492 2505 2506 2514 2528\n",
      " 2532 2552 2570 2598 2599 2603]\n",
      "TRAIN: [   0    1    2 ..., 2602 2603 2605] TEST: [   8   13   16   29   32   35   49   56   60   68   71   75   96  110  114\n",
      "  134  147  155  186  211  212  218  226  231  241  243  244  247  258  265\n",
      "  285  293  304  336  339  354  355  358  362  367  372  377  401  406  420\n",
      "  426  431  432  435  445  450  455  456  464  471  494  499  500  513  520\n",
      "  524  533  540  542  548  549  552  554  576  580  585  589  593  611  631\n",
      "  642  649  668  677  678  679  693  706  725  737  752  769  782  788  803\n",
      "  814  862  871  875  881  884  887  889  939  940  942  943  948  957  960\n",
      "  970  984  994  999 1014 1016 1031 1044 1060 1064 1065 1075 1105 1120 1123\n",
      " 1124 1128 1143 1164 1171 1184 1189 1200 1218 1227 1229 1245 1248 1252 1265\n",
      " 1299 1310 1312 1315 1319 1336 1340 1354 1361 1403 1407 1436 1444 1446 1451\n",
      " 1455 1463 1464 1476 1495 1498 1501 1505 1511 1519 1554 1572 1586 1591 1604\n",
      " 1607 1626 1644 1650 1652 1654 1655 1662 1669 1670 1683 1698 1716 1721 1738\n",
      " 1739 1741 1746 1766 1767 1771 1776 1794 1806 1837 1850 1870 1880 1888 1893\n",
      " 1894 1922 1936 1944 1951 1953 1981 1984 1992 2016 2029 2043 2060 2062 2065\n",
      " 2070 2082 2096 2111 2125 2126 2130 2132 2157 2167 2174 2192 2193 2196 2205\n",
      " 2216 2224 2231 2243 2250 2255 2268 2301 2307 2314 2323 2330 2337 2363 2368\n",
      " 2403 2404 2423 2436 2440 2461 2466 2481 2516 2537 2540 2541 2547 2557 2563\n",
      " 2572 2580 2586 2589 2600 2604]\n",
      "TRAIN: [   0    1    2 ..., 2602 2603 2604] TEST: [  38   44   51   59   78   81   83   88   97  103  111  119  123  129  131\n",
      "  165  183  188  205  213  238  239  261  263  269  313  316  328  338  349\n",
      "  356  363  371  374  382  395  397  410  439  448  463  466  472  476  484\n",
      "  490  493  507  510  514  528  541  571  599  601  608  613  625  635  645\n",
      "  656  660  681  685  695  697  729  751  761  771  779  783  784  808  819\n",
      "  826  833  844  846  849  853  858  867  874  879  904  907  911  919  934\n",
      "  947  969  993 1019 1034 1035 1039 1057 1067 1084 1088 1089 1094 1102 1115\n",
      " 1121 1125 1156 1158 1191 1196 1220 1223 1224 1233 1238 1260 1262 1268 1269\n",
      " 1274 1276 1281 1290 1291 1296 1307 1311 1318 1320 1321 1324 1335 1344 1351\n",
      " 1360 1364 1375 1382 1383 1391 1401 1408 1410 1415 1419 1420 1430 1439 1440\n",
      " 1442 1475 1477 1494 1502 1510 1524 1527 1529 1534 1557 1564 1609 1613 1614\n",
      " 1618 1624 1630 1636 1639 1651 1658 1687 1691 1693 1695 1700 1706 1711 1733\n",
      " 1743 1756 1772 1784 1804 1811 1830 1831 1833 1841 1842 1857 1881 1882 1887\n",
      " 1906 1912 1918 1959 1977 1991 2004 2014 2086 2094 2101 2103 2104 2106 2110\n",
      " 2114 2118 2127 2147 2179 2184 2199 2214 2220 2226 2227 2232 2239 2241 2275\n",
      " 2286 2287 2294 2318 2327 2329 2332 2342 2348 2373 2375 2411 2420 2428 2433\n",
      " 2437 2439 2451 2459 2464 2472 2474 2489 2503 2521 2529 2530 2534 2535 2545\n",
      " 2546 2551 2553 2590 2605]\n",
      "TRAIN: [   0    1    2 ..., 2603 2604 2605] TEST: [  12   20   28   46   50   62   74   79   90   95  101  105  115  116  120\n",
      "  127  128  138  143  150  158  167  172  181  193  208  222  225  228  230\n",
      "  235  236  242  255  266  284  288  290  301  306  331  332  337  344  345\n",
      "  346  352  366  370  380  389  394  396  403  409  413  417  421  441  462\n",
      "  492  495  496  515  523  531  545  559  566  588  592  612  614  617  622\n",
      "  626  628  630  662  669  675  683  690  707  719  734  742  747  753  765\n",
      "  777  787  790  798  822  824  857  864  870  877  901  912  915  920  922\n",
      "  959  968 1024 1030 1037 1054 1061 1062 1066 1072 1086 1092 1095 1142 1168\n",
      " 1169 1178 1181 1182 1186 1214 1230 1234 1237 1258 1282 1286 1288 1309 1313\n",
      " 1342 1356 1365 1372 1394 1402 1404 1406 1433 1437 1481 1508 1509 1517 1522\n",
      " 1545 1546 1575 1576 1583 1584 1595 1600 1616 1620 1623 1628 1629 1638 1649\n",
      " 1659 1676 1682 1685 1688 1692 1730 1745 1751 1755 1782 1788 1791 1793 1796\n",
      " 1797 1799 1807 1810 1812 1815 1835 1843 1856 1866 1884 1891 1911 1917 1926\n",
      " 1932 1958 1962 1965 1986 1990 1995 2002 2041 2047 2048 2049 2066 2068 2077\n",
      " 2079 2098 2112 2113 2128 2137 2142 2148 2155 2162 2168 2170 2200 2206 2209\n",
      " 2211 2212 2221 2234 2252 2261 2277 2291 2299 2313 2350 2353 2361 2366 2369\n",
      " 2370 2374 2384 2388 2426 2445 2448 2449 2455 2476 2486 2504 2513 2533 2539\n",
      " 2542 2565 2573 2583 2595]\n",
      "TRAIN: [   1    2    4 ..., 2603 2604 2605] TEST: [   0    3    7   21   26   63   93  100  112  126  153  160  163  164  174\n",
      "  237  246  280  281  282  292  321  325  327  329  334  343  348  350  365\n",
      "  375  387  400  404  407  419  424  428  437  447  449  451  460  470  497\n",
      "  504  550  573  577  584  586  594  595  603  604  605  606  624  627  640\n",
      "  647  650  664  671  673  680  691  694  696  698  699  709  732  736  738\n",
      "  739  741  754  780  786  800  804  827  830  834  837  845  848  851  854\n",
      "  859  869  873  902  903  929  932  941  945  950  952  975  990 1004 1006\n",
      " 1011 1028 1040 1046 1048 1090 1111 1113 1130 1131 1133 1144 1149 1159 1163\n",
      " 1177 1179 1194 1201 1202 1209 1215 1219 1221 1243 1247 1249 1250 1251 1253\n",
      " 1289 1298 1305 1306 1308 1314 1331 1333 1337 1348 1353 1369 1384 1389 1398\n",
      " 1409 1413 1416 1425 1438 1441 1443 1461 1468 1479 1480 1497 1514 1532 1541\n",
      " 1542 1551 1556 1558 1562 1566 1574 1579 1582 1596 1608 1617 1660 1667 1671\n",
      " 1672 1690 1705 1707 1722 1734 1744 1747 1769 1800 1805 1834 1838 1844 1847\n",
      " 1849 1862 1868 1879 1883 1889 1915 1924 1933 1938 1941 1963 1967 1971 1975\n",
      " 1978 1993 2003 2006 2009 2021 2040 2042 2051 2107 2136 2150 2152 2153 2154\n",
      " 2180 2182 2185 2189 2195 2215 2247 2271 2295 2304 2306 2309 2315 2331 2340\n",
      " 2347 2377 2379 2380 2385 2390 2412 2424 2427 2443 2454 2470 2473 2488 2501\n",
      " 2523 2527 2591 2593 2602]\n",
      "TRAIN: [   0    1    2 ..., 2603 2604 2605] TEST: [  24   25   67   84   86   91   94   99  130  136  146  151  166  168  176\n",
      "  180  197  199  201  207  209  216  221  256  257  273  274  275  277  291\n",
      "  297  307  323  324  368  373  388  423  429  430  433  469  508  509  525\n",
      "  537  544  555  556  560  591  607  623  637  639  659  705  714  730  749\n",
      "  755  756  763  767  770  774  797  802  807  809  816  821  835  843  860\n",
      "  865  872  885  888  894  908  925  928  931  954  956  967  972  973  976\n",
      " 1007 1020 1022 1033 1053 1071 1085 1104 1107 1112 1134 1141 1152 1153 1155\n",
      " 1162 1167 1172 1176 1198 1204 1206 1207 1208 1241 1272 1278 1297 1304 1316\n",
      " 1329 1345 1346 1350 1352 1381 1392 1395 1400 1429 1434 1435 1445 1447 1466\n",
      " 1469 1470 1472 1483 1488 1531 1536 1552 1561 1563 1565 1578 1589 1605 1619\n",
      " 1634 1640 1641 1645 1653 1684 1699 1701 1718 1720 1723 1731 1740 1750 1777\n",
      " 1778 1792 1795 1822 1823 1828 1863 1871 1877 1896 1899 1904 1905 1908 1910\n",
      " 1913 1920 1925 1930 1940 1954 1956 1966 1970 1973 1987 2008 2011 2022 2023\n",
      " 2024 2036 2046 2059 2071 2076 2080 2081 2084 2089 2091 2105 2117 2120 2121\n",
      " 2135 2139 2141 2146 2159 2163 2169 2171 2176 2177 2187 2197 2217 2222 2237\n",
      " 2251 2257 2260 2280 2282 2292 2322 2334 2335 2338 2339 2344 2362 2371 2383\n",
      " 2389 2415 2418 2425 2431 2435 2446 2483 2490 2494 2496 2517 2524 2554 2558\n",
      " 2568 2577 2578 2584 2587]\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train_index, test_index in cv.split(data):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that ShuffleSplit has selected a random set of observations from the index of our data set for each fold of our cross-validation. Let's look at the size of our training and test set for each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 2345 TEST: 261\n",
      "TRAIN: 2345 TEST: 261\n",
      "TRAIN: 2345 TEST: 261\n",
      "TRAIN: 2345 TEST: 261\n",
      "TRAIN: 2345 TEST: 261\n",
      "TRAIN: 2345 TEST: 261\n",
      "TRAIN: 2346 TEST: 260\n",
      "TRAIN: 2346 TEST: 260\n",
      "TRAIN: 2346 TEST: 260\n",
      "TRAIN: 2346 TEST: 260\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train_index, test_index in cv.split(data):\n",
    "    print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try using KFold to train and test our model on 10 different subsets of our data. Below we set our cross-validator as 'cv'. We then loop through the various splits in our data that cv creates and use it to make our training and test sets. We then use our training set to fit a Logistic Regression model and generate predictions from our test set, which we compare to the actual outcomes we observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 52.4\n",
      "Precision: 58.7\n",
      "Precision: 52.4\n",
      "Precision: 67.2\n",
      "Precision: 54.7\n",
      "Precision: 50.0\n",
      "Precision: 52.8\n",
      "Precision: 57.4\n",
      "Precision: 60.5\n",
      "Precision: 44.1\n"
     ]
    }
   ],
   "source": [
    "## Define function\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "## Create for-loop\n",
    "for train_index, test_index in cv.split(data):\n",
    "\n",
    "    ## Define training and test sets\n",
    "    X_train = data.loc[train_index].drop(['activity', 'month', 'WARD'], axis=1)\n",
    "    y_train = data.loc[train_index]['activity']\n",
    "    X_test = data.loc[test_index].drop(['activity', 'month', 'WARD'], axis=1)\n",
    "    y_test = data.loc[test_index]['activity']\n",
    "        \n",
    "    ## Fit model\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    ## Generate predictions\n",
    "    predicted = clf.predict(X_test)\n",
    "    \n",
    "    ## Compare to actual outcomes and return precision\n",
    "    print('Precision: '+str(100 * round(precision_score(y_test, predicted),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can see that, for the most part, about 50 to 60 percent of the inspections our model predicts will lead our inspectors to rat burrows actually do. This is a modest improvement over our inspectors' current performance in the field. Based on these results, if we used our models to determine which locations our inspectors go to in the field, we'd probably see a 10 to 20 point increase in their likelihood of finding rat burrows.\n",
    "\n",
    "## Exercise 1\n",
    "\n",
    "Try running the k-fold cross-validation a few times with the same random state. Then try running it a few times with different random states. How do the results change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to point out here that, because we have TIME SERIES data, the same Census blocks may be appearing in our training AND our test sets. This is a challenge to ensuring that our training and test samples are INDEPENDENT. While Rodent Control does not inspect the same blocks every month, some of the same blocks may be re-inspected from month to month depending on where 311 requests are coming from. \n",
    "\n",
    "However, this also affords us an opportunity. More than likely, when we make predictions about which inspections will lead our inspectors to rat burrows, we are interested in predicting FUTURE inspections with observations from PAST inspections. In this case, cross-validating over time can be a very good way of looking at how well our models are performing. \n",
    "\n",
    "Cross-validating over time requires more than just splitting by month. Rather, we will use observations from each month as a test set and train our models on all PRIOR months. Which we do below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation by Month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by seeing what our cross-validation sets look like. Below, we loop through each of the sets to see which months end up in our training and test sets. You can see that as we move from month to month, we have more and more past observations in our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Month: [2] Training Months: [1]\n",
      "Test Month: [3] Training Months: [1 2]\n",
      "Test Month: [4] Training Months: [1 2 3]\n",
      "Test Month: [5] Training Months: [1 2 3 4]\n",
      "Test Month: [6] Training Months: [1 2 3 4 5]\n",
      "Test Month: [7] Training Months: [1 2 3 4 5 6]\n",
      "Test Month: [8] Training Months: [1 2 3 4 5 6 7]\n",
      "Test Month: [9] Training Months: [1 2 3 4 5 6 7 8]\n",
      "Test Month: [10] Training Months: [1 2 3 4 5 6 7 8 9]\n",
      "Test Month: [11] Training Months: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "Test Month: [12] Training Months: [ 1  2  3  4  5  6  7  8  9 10 11]\n"
     ]
    }
   ],
   "source": [
    "months = np.sort(data.month.unique())\n",
    "\n",
    "for month in range(2,13):\n",
    "    test = data[data.month==month]\n",
    "    train = data[(data.month < month)]\n",
    "\n",
    "    print('Test Month: '+str(test.month.unique()), 'Training Months: '+str(train.month.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for Month 2: 79.2\n",
      "Precision for Month 3: 67.3\n",
      "Precision for Month 4: 48.9\n",
      "Precision for Month 5: 63.4\n",
      "Precision for Month 6: 61.9\n",
      "Precision for Month 7: 68.8\n",
      "Precision for Month 8: 66.2\n",
      "Precision for Month 9: 67.6\n",
      "Precision for Month 10: 57.3\n",
      "Precision for Month 11: 67.6\n",
      "Precision for Month 12: 70.5\n"
     ]
    }
   ],
   "source": [
    "months = np.sort(data.month.unique())\n",
    "\n",
    "for month in range(2,13):\n",
    "\n",
    "    test = data[data.month==month]\n",
    "    train = data[(data.month < month)]\n",
    "    X_test = test.drop(['activity', 'month', 'WARD'], axis=1)\n",
    "    y_test = test['activity']\n",
    "    X_train = test.drop(['activity', 'month', 'WARD'], axis=1)\n",
    "    y_train = test['activity']\n",
    "        \n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "    predicted = clf.predict(X_test)\n",
    "    print('Precision for Month '+str(month)+': '+str(100*round(precision_score(y_test, predicted),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model seems to be performing even better when we cross-validate over months, possibly because we're structuring the cross-validation such that inspections in some of the same blocks appear consistently over time. \n",
    "\n",
    "## Exercise 2\n",
    "\n",
    "Try re-creating this cross-validation, but with the training set restricted to only the 3 months prior to the test set. Now do the same with the last 1 and 2 months. Do the results change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may still be concerned about the independence of our training and test sets. In particular, as I've pointed out, the same Census blocks may appear repeatedly in our data over time. In this case, it may be good to cross-validate geographically to make sure that our model is performing well in different parts of the city. In particular, we know that requests for rodent abatement (and rats themselves) are more common in some parts of the city than in others. In particular, rats are more common in the more densely-populated parts of downtown and less common in less densely-populated places like Wards 3, 7, and 8. Therefore, we may be interested in cross-validating by ward. \n",
    "\n",
    "Again, this is as simple as looping through each of the 8 wards, holding out each ward as a test set and training the models on observations from the remaining wards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validate by Ward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    419\n",
       "2    477\n",
       "3    105\n",
       "4    496\n",
       "5    355\n",
       "6    458\n",
       "7    154\n",
       "8    142\n",
       "Name: WARD, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.WARD.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for Ward 1: 59.0\n",
      "Precision for Ward 2: 60.2\n",
      "Precision for Ward 3: 81.2\n",
      "Precision for Ward 4: 61.1\n",
      "Precision for Ward 5: 58.7\n",
      "Precision for Ward 6: 45.5\n",
      "Precision for Ward 7: 0.0\n",
      "Precision for Ward 8: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter.casey\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for ward in np.sort(data.WARD.unique()):\n",
    "\n",
    "    test = data[data.WARD == ward]\n",
    "    train = data[data.WARD != ward]\n",
    "    X_test = test.drop(['activity', 'month', 'WARD'], axis=1)\n",
    "    y_test = test['activity']\n",
    "    X_train = test.drop(['activity', 'month', 'WARD'], axis=1)\n",
    "    y_train = test['activity']\n",
    "        \n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "    predicted = clf.predict(X_test)\n",
    "    print('Precision for Ward '+str(ward)+': '+str(100*round(precision_score(y_test, predicted),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the model performs very well predicting the outcomes of inspections in wards 1 through 4, but less well in wards 5 though 8. In wards 7 and 8 in particular, the model fails to predict any positive cases. This means that our model may be overfit to observations in Wards 1 through 6, and we may want to re-evaluate our approach. \n",
    "\n",
    "## Exercise 3\n",
    "\n",
    "Explore the data and our model and try to come up with some reasons that the model is performing poorly on Wards 7 and 8. Is there a way we can fix the model to perform better on those wards? How might we fix the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "Now try running some cross-validations with the data from your project. What are some different ways you might slice the data you're using for your project? Try them out here. This will be a good way to begin making progress toward your final submission. \n",
    "\n",
    "PLEASE REMEMBER TO SUBMIT THIS HOMEWORK BY CLASS TIME ON THURSDAY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
